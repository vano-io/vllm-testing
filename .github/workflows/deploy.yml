env:
  MODEL_ID: Qwen/Qwen3-4B-AWQ
  MODEL_DIR: hf-model
  IMAGE_NAME: qwen3-4b-awq-vllm
  REGISTRY: hub.docker.com
  REGISTRY_NAME: josephvano  # replace with your Docker Hub username

name: Publish Docker Image

on:
  push:
    branches: [ main ]

jobs:
  version:
    runs-on: ubuntu-latest
    outputs:
      version: ${{ steps.vars.outputs.version }}
    steps:
      - uses: actions/checkout@v5

      - name: Node
        uses: actions/setup-node@v5
        with:
          node-version: '24'
      - name: Capture next version for web
        id: vars
        env:
          GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}
        run: |
          npm install semantic-release @semantic-release/github @semantic-release/git @semantic-release/exec @semantic-release/commit-analyzer @semantic-release/release-notes-generator @semantic-release/changelog conventional-changelog
          DEBUG=semantic-release* semantic-release --dry-run --generate-notes false
          cat VERSION
          echo ::set-output name=version::$(cat VERSION)
      - name: Echo version
        run: echo ${{ steps.vars.outputs.version }}
  publish:
    needs: [ version ]
    runs-on: ubuntu-latest

    steps:
      - uses: actions/checkout@v5

      # Optional but recommended for large downloads:
      # caches HF downloads across workflow runs.
      - name: Cache Hugging Face files
        uses: actions/cache@v4
        with:
          path: |
            ~/.cache/huggingface
          key: hf-${{ runner.os }}-${{ env.MODEL_ID }}
          restore-keys: |
            hf-${{ runner.os }}-

      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: "3.12"
      - name: Install huggingface_hub
        run: |
          python -m pip install --upgrade pip
          pip install "huggingface_hub>=0.23.0" "hf-transfer>=0.1.8"

      - name: Download model snapshot to workspace
        env:
          HF_TOKEN: ${{ secrets.HF_TOKEN }} # optional; only needed if model is gated/private
          HF_HUB_ENABLE_HF_TRANSFER: "1"
        run: |
          python - <<'PY'
          import os
          from huggingface_hub import snapshot_download

          model_id = os.environ["MODEL_ID"]
          out_dir = os.environ["MODEL_DIR"]
          token = os.environ.get("HF_TOKEN") or None

          # This downloads the *full repo snapshot* into MODEL_DIR (no symlinks)
          snapshot_download(
              repo_id=model_id,
              local_dir=out_dir,
              local_dir_use_symlinks=False,
              token=token,
          )
          print(f"Downloaded {model_id} -> {out_dir}")
          PY

      - name: Show model size (sanity check)
        run: |
          du -sh $MODEL_DIR || true
          find $MODEL_DIR -maxdepth 2 -type f | head -n 20

      - name: Set up Docker Buildx
        uses: docker/setup-buildx-action@v3

      - name: Set up Docker Buildx
        uses: docker/setup-buildx-action@v3

      - name: Log in to Docker Hub
        uses: docker/login-action@v2
        with:
          username: ${{ secrets.DOCKER_USERNAME }}
          password: ${{ secrets.DOCKER_PASSWORD }}

      - name: Build and push Docker image
        uses: docker/build-push-action@v4
        with:
          push: true
          tags: |
            ${{ env.REGISTRY_NAME }}/${{ env.IMAGE_NAME }}:latest
            ${{ env.REGISTRY_NAME }}/${{ env.IMAGE_NAME }}:${{ github.sha }}
            ${{ env.REGISTRY_NAME }}/${{ env.IMAGE_NAME }}:${{ needs.version.outputs.version }}
          build-args: |
            MODEL_ID=${{ env.MODEL_ID }}
            MODEL_DIR=${{ env.MODEL_DIR }}